<h2>Dataset</h2>

<p>
    The starting kit provides utility that can be used to train and test your agent submission.
</p>

<p>In addition to building your own scenarios, you are also allowed to:</p>
<ul>
<li>Modify your agent's reward function</li>
<li>Modify any code used for your agent</li>
<li>Build your agent off of any baseline in the starting kit</li>
<li>Change the maximum number of steps per episode your agent is allowed to take</li>
<li>Change the amount of time per timestep</li>
<li>Change the seeding of the environment and scenarios</li>
</ul>

<p>
    The only two requirements are that your action space converts to [dx, dy], and that
    your agent uses the allowable observation spaces. If you have concerns
    about whether your agent will be accepted, the starting kit provides the exact
    evaluation script we will use to evaluate your agent, and instructions on how to use
    this evaluation script. If your agent successfully runs in the evaluation script, it
    will have met all the requirements of a valid submission.
</p>

<p>
    The evaluation scenarios for both Track 1 and Track 2 were created using the
    provided maps, and thus, will be similar to the training scenarios that you create
    for your agent. See the evaluation section for more details.
</p>
